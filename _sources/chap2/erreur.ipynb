{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Notion d'erreur sur une mesure\n",
    "\n",
    "Comme nous l'avons discuté dans le chapitre précédent, un des objectifs de la physique expérimentale est d'estimer les paramètres physiques des modèles que l'on considère, et ce avec une certaine précision.\n",
    "En effet si on se donne un modèle donnant la distribution de mesures expérimentales en fonction d'un ou plusieurs paramètres, on va vouloir tester la validité de ce modèle en estimant tout d'abord les valeurs des paramètres de ce modèle.\n",
    "Ces estimations sont obtenues à partir d'un échantillon de mesures de certaines quantités issues d'une ou plusieurs expériences.\n",
    "En général, on va associer à chaque estimation une **incertitude** (aussi appelée **erreur**) qui caractérise la précision que l'on \\textit{pense} avoir sur cette estimation.\n",
    "Cette incertitude permet aussi de comparer deux estimations, ou bien une estimation et une valeur théorique attendue et décider si elles sont en accord.\n",
    "\n",
    "## Notion d'estimateurs\n",
    "\n",
    "Un **estimateur** $\\hat{A}$ d'un paramètre physique $A$ est une fonction des mesures expérimentales $\\vec{x}$ qui renvoie une valeur approchée de la vraie valeur $A_0$ de $A$.\n",
    "Puisque $\\hat{A}$ est une fonction de mesures, c'est une variable aléatoire avec une pdf associée $f_{\\hat{A}}$.\n",
    "\n",
    "Intuitivement, on peut voir que la valeur moyenne de cet estimateur $\\int a\\times f_{\\hat{A}}\\mathrm{d}a$ doit être proche (ou égale) de sa valeur vraie et que la pdf de cet estimateur doit être relativement peu étalé afin qu'une réalisation de cet estimateur (avec des mesures expérimentales de $\\vec{x}$) ait de grandes chances d'être proche de la valeur vraie.\n",
    "\n",
    "Un bon estimateur doit donc respecter plusieurs propriétés:\n",
    "\n",
    "- Un estimateur doit converger vers la valeur vraie du paramètre associé.\n",
    "Si on considère un échantillon de mesures $\\vec{x}$ de taille infinie, l'estimation de $A$ avec $\\hat{A}$ doit être strictement égale à la valeur vraie $A_0$:\n",
    "\\begin{equation}\n",
    "    \\lim _{n\\rightarrow \\infty} \\hat{A} = A_0.\n",
    "\\end{equation}\n",
    "- L'estimateur ne doit pas être biaisé, c'est à dire que la moyenne (en probabilité) de $\\hat{A}$ (que l'on note $\\bar{\\hat{A}}$ et calcule avec l'équation {eq}`esperance`) doit être égale à la valeur vraie $A_0$.\n",
    "On définit le biais comme l'écart entre la valeur moyenne et la valeur vraie:\n",
    "\n",
    "$$ \n",
    "b(\\hat{A}) = \\mathbb{E}(\\hat{A}) - A_0.\n",
    "$$ (def-biais)\n",
    "\n",
    "Un estimateur peut être non biaisé asymptotiquement, c'est-à-dire non biaisé pour une taille d'échantillon infinie.\n",
    "Cette propriété et la précédente sont reliées: on peut démontrer qu'un estimateur convergent vers la valeur vraie $A_0$ est non biaisé asymptotiquement.\n",
    "- Un estimateur doit être efficace, c'est-à-dire qu'il doit converger le plus rapidement possible vers la vraie valeur du paramètre $A$.\n",
    "Grossièrement, plus un estimateur converge rapidement, plus son étalement diminue rapidement à mesure que la taille de l'échantillon de mesures $\\vec{x}$ augmente.\n",
    "\n",
    "## Définition d'un erreur\n",
    "\n",
    "Souvent, quand on parle d'estimation d'un paramètre, on sous-entend que l'estimation donne une unique valeur numérique du paramètre estimé.\n",
    "Ce type d'estimation renvoie à l'idée que l'estimateur est la \\textit{valeur centrale de la série de mesures}: les estimateurs associés sont appelés **estimateurs paramétriques** et doivent respecter les propriétés de la section précédente.\n",
    "\n",
    "Au lieu de donner une valeur unique estimant le paramètre $A$, on pourrait aussi définir un intervalle $[a_1, a_2]$ qui contient vraisemblablement la valeur vraie.\n",
    "La largeur de cet intervalle correspond à la précision de la mesure ou des mesures que l'on a fait.\n",
    "Par exemple, lorsqu'on utilise un pèse-personne pour estimer sa masse, la valeur affichée va être de $71.3 mathrm{kg}\\pm 0.1 mathrm{kg}$, où le $\\pm 0.1 mathrm{kg}$ est la précision de la balance avancée par le constructeur de la balance: cela définit donc un intervalle $[ 71.2 mathrm{kg}, 71.4 mathrm{kg}]$ dans lequel il est vraisemblable que notre vraie masse se trouve réellement.\n",
    "Ce type d'estimation du paramètre se nomme **estimation par intervalle**.\n",
    "\n",
    "La définition d'un intervalle contenant vraisemblablement la valeur vraie revient finalement à définir une valeur centrale de l'intervalle comme étant la valeur de l'estimateur $\\hat{A}$ et une **erreur** sur cet estimateur, notée généralement $\\sigma _{\\hat{A}}$, correspondant à l'étalement des valeurs vraisemblables de $A_0$.\n",
    "Si cet étalement tend vers 0 lorsque la taille de l'échantillon tend vers l'infini ou \n",
    "\\begin{equation}\n",
    "    \\lim _{n\\rightarrow \\infty} \\sigma _{\\hat{A}}^2 = 0,\n",
    "\\end{equation}\n",
    "l'estimateur $\\hat{A}$ est convergent: dans la limite infinie, on a alors un estimateur dont la moyenne est la valeur vraie $A_0$ et de variance nulle donc cet estimateur donne la vraie valeur de $A$.\n",
    "\n",
    "Un point important à remarquer est qu'à chaque estimation de l'intervalle est associée notre certitude de la présence de la valeur vraie dans cet intervalle: être sûr et certain n'est bien évidemment pas la même chose qu'en être sur à 50 % ou pas sûr du tout.\n",
    "Aussi, un intervalle correspondant à un niveau de certitude de 95 % relativement large pourrait être équivalent à un niveau de taille plus faible avec une certitude associée plus faible.\n",
    "Généralement, en sciences expérimentales, les intervalles que l'on définit ont une certitude associée de 68 %: ce choix à priori arbitraire est en fait relié aux intervalles pour des pdf gaussiennes.\n",
    "Cependant nous n'aborderons pas en détails cette notion, mais il est important de garder en tête cela lorsque l'on mesure des quantités en physique expérimentale: à quel point est on sûr que l'intervalle que l'on vient de définir contient la valeur vraie du paramètre?\n",
    "\n",
    "## Quelques exemples d'estimateurs empiriques\n",
    "\n",
    "Un estimateur très répandu est celui de l'estimateur $\\hat{\\mu}$ de la moyenne d'un échantillon de valeurs $\\left\\{x_i\\right\\}$ non corrélée entre elles.\n",
    "Si chaque valeur $x_i$ est une réalisation d'une même variable $X$, les $x_i$ valent en moyenne $\\mathbb{E}(x_i) = \\mu$ et ont une variance $var(x_i) = \\sigma ^2$.\n",
    "On peut vérifier que cet estimateur, appelé **estimateur de la moyenne empirique** n'est pas biaisé.\n",
    "En effet, on peut démontrer\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}(\\hat{\\mu}) = \\mathbb{E}\\left( \\frac{1}{n}\\sum _i x_i \\right) = \\frac{1}{n}\\sum _i \\mathbb{E}(x_i) = \\frac{1}{n} \\sum _i \\mu = \\mu,\n",
    "$$ (estimateur-moyenne)\n",
    "\n",
    "ce qui veut dire que le biais de cet estimateur est nul d'après l'équation {eq}`def-biais`:\n",
    "\\begin{equation}\n",
    "    b(\\hat{\\mu}) = \\mathbb{E}(\\hat{\\mu}) - \\mu = 0.\n",
    "\\end{equation}\n",
    "\n",
    "On peut étudier la vitesse de convergence de cet estimateur en calculant la variance de cet estimateur [^detail-var]:\n",
    "\\begin{equation}\n",
    "    \\sigma ^2 _{\\hat{\\mu}} = var\\left( \\hat{\\mu} \\right) = var \\left( \\frac{1}{n} \\sum _i x_i  \\right) = \\frac{1}{n^2} \\sum _i var \\left(  x_i  \\right) = \\frac{1}{n^2}  \\sum _i \\sigma ^2 = \\frac{\\sigma^2}{n}.\n",
    "\\end{equation}\n",
    "On voit donc que pour un échantillon de taille infinie, la variance de cet estimateur vaut zéro, ce qui en fait un estimateur convergent.\n",
    "On peut aussi remarquer la vitesse de convergence de cet estimateur.\n",
    "En effet, l'incertitude notée $\\Delta \\hat{\\mu}$ sur cet estimateur vaut:\n",
    "\n",
    "$$\n",
    "    \\Delta \\hat{\\mu} = \\frac{\\sigma}{\\sqrt{n}},\n",
    "$$ (erreur-moyenne)\n",
    "\n",
    "avec $\\sigma$ représentant l'erreur sur les valeurs des $x_i$.\n",
    "Cela veut dire que l'incertitude $\\Delta \\hat{\\mu}$ sur une moyenne est toujours plus faible que celle sur les valeurs individuelles et qu'il est toujours possible d'améliorer l'incertitude $\\Delta \\hat{\\mu}$: si on augmente la taille de l'échantillon par un facteur 4, on réduit l'incertitude sur la moyenne par un facteur 2.\n",
    "\n",
    "Un autre estimateur empirique d'intérêt est celui de la variance:\n",
    "\\begin{equation}\n",
    "    \\hat{\\sigma} ^2 = \\frac{1}{n-1} \\sum _{i=0} ^n (x_i - \\bar{x})^2.\n",
    "\\end{equation}\n",
    "De façon similaire à la moyenne, on peut démontrer que cet estimateur est non biaisé avec une moyenne $\\mu _{\\hat{\\sigma}^2} = \\sigma ^2$ correspondant à la valeur vraie.\n",
    "On peut remarquer que cet estimateur diffère de la définition statistique de la variance donnée par l'équation {eq}`def-variance-stats` par un facteur $\\frac{n}{n-1}$: cela semble assez évident puisque si le nombre de mesures vaut $n=1$, on ne peut pas estimer la variance de l'échantillon.\n",
    "Il est important aussi de noter que cet estimateur de la variance ne correspond pas à l'erreur sur la moyenne que nous avons établie avec l'équation {eq}`erreur-moyenne`: en effet, celui-ci ne diminue pas lorsque $n$ augmente, mais correspond véritablement à la variance de la variable aléatoire de mesure.\n",
    "\n",
    "## Classification des erreurs\n",
    "\n",
    "L'estimateur de la moyenne {eq}`estimateur-moyenne` est un estimateur qui converge vers la valeur moyenne vraie de la variable aléatoire associée.\n",
    "Si on répète les mesures, les échantillons obtenus vont vraisemblablement se répartir autour de cette valeur vraie: certaines valeurs seront au dessus et certains en dessous.\n",
    "\n",
    "L'erreur que l'on fait alors sur la moyenne {eq}`erreur-moyenne` est appelée **erreur statistique**, puisque due à la statistique de l'échantillon collecté.\n",
    "Ce type d'erreur se distingue des erreurs dites **systématiques** qui se caractérisent par le fait que des mesures répétées vont donner **systématiquement** des valeurs supérieures à la valeur vraie ou bien des valeurs inférieures à la valeur vraie.\n",
    "Si l'on faisait la moyenne de mesures entachées par des erreurs systématiques, celle-ci ne va pas tendre vers la valeur vraie de la moyenne, mais vers une valeur systématiquement plus grande ou plus faible que la valeur vraie correspondant à un biais.\n",
    "\n",
    "Il est souvent difficile de détecter ce type d'erreur puisqu'on ne connait généralement pas la valeur vraie (c'est d'ailleurs pour la déterminer que l'on fait des mesures...).\n",
    "Il est donc nécessaire de réfléchir aux phénomènes physiques qui peuvent causer ce type d'erreurs: il est en effet parfois possible de corriger ces biais.\n",
    "Si cela n'est pas possible ou bien si l'on n'est pas très sur de la correction que l'on fait, on va alors associer à l'estimateur une valeur correspondant à une estimation de notre incertitude sur ce biais: on l'appellera **incertitude systématique**.\n",
    "Cette valeur s'ajoutera alors à la valeur sur l'incertitude statistique, par exemple celle donnée par l'équation {eq}`erreur-moyenne` dans le cas de l'estimateur de la moyenne.\n",
    "\n",
    "Les erreurs systématiques peuvent donc provenir de plusieurs sources:\n",
    "\n",
    "- la résolution du détecteur due à la précision de lecture de l'évaluateur (lecture d'une distance grâce à une règle graduée plus ou moins finement, lecture d'une quantité sur un instrument dont le cadrant affiche des valeurs changeantes);\n",
    "- des facteurs environnementaux causant des effets sur le dispositif de mesure (par exemple, les changements de température de la pièce entre le matin et l'après-midi peuvent causer des variabilités dans la mesure d'une même quantité par un instrument);\n",
    "- la variabilité de la calibration de l'instrument de mesure (en recalibrant l'instrument et mesurant la même quantité, la valeur donnée par l'instrument pourrait changer);\n",
    "- la dérive ou le vieillissement d'un instrument;\n",
    "- les erreurs de l'expérimentateur lors du report des mesures (souvent les plus dures à déceler...).\n",
    "\n",
    "(content:propagation-erreurs)=\n",
    "## Propagation des erreurs\n",
    "\n",
    "Lorsque des mesures sont faites, les quantités d'intérêt doivent être calculées à l'aide de formules ou de fonctions impliquant ces données.\n",
    "Cependant ces fonctions ont souvent des paramètres qui possèdent des incertitudes qu'il faut prendre en compte ou **propager** dans le calcul de l'incertitude sur la grandeur d'intérêt.\n",
    "Si, par exemple, la quantité d'intérêt $z$ dépend d'une mesure $x$ par la fonction $f(x)$ avec $y$ est un paramètre de cette fonction, l'incertitude sur $z$ sera $\\Delta z = \\Delta f(x,\\Delta x, y, \\Delta y)$.\n",
    "\n",
    "Une bonne approximation pour le calcul de l'incertitude $\\Delta f$ sur la quantité $f$ dépendant de $n$ variables $x_i$ est donnée par \n",
    "\n",
    "$$ \n",
    "  \\Delta f^2 = \\sum _{i=1}^n \\left(\\frac{\\partial f}{\\partial x_i}\\right) ^2 \\Delta x_i ^2 + 2 \\sum _{i, j<i} cov(x_i, x_j) \\left\\vert \\frac{\\partial f}{\\partial x_i} \\frac{\\partial f}{\\partial x_j} \\right\\vert.\n",
    "$$ (propagation-erreur-correlee)\n",
    "\n",
    "Si les variables $x_i$ ne sont pas corrélées entre elles (i.e. $cov (x_i, x_j)=0$), alors l'expression se simplifie en \n",
    "\n",
    "$$\n",
    "  \\Delta f^2 = \\sum _{i=1}^n \\left(\\frac{\\partial f}{\\partial x_i}\\right) ^2 \\Delta x_i ^2.\n",
    "$$ (propagation-erreur-non-correlee)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```{admonition} Exemple\n",
    "Quelques exemples de formules classiques de propagation d'incertitudes où on néglige les corrélations entre les variables:\n",
    "\n",
    "- pour $f(x,y) = x+y$, \n",
    "  \\begin{equation}\n",
    "    \\Delta f^2 = \\Delta x^2 + \\Delta y^2;\n",
    "  \\end{equation}\n",
    "- pour $f(x,y) = x-y$, \n",
    "  \\begin{equation}\n",
    "   \\Delta f^2 = \\Delta x^2 + \\Delta y^2;\n",
    "  \\end{equation}\n",
    "- pour $f(x,y) = x\\times y$, \n",
    "  \\begin{equation}\n",
    "    \\frac{\\Delta f^2}{f^2} = \\frac{\\Delta x^2}{x^2} + \\frac{\\Delta y^2}{y^2};\n",
    "  \\end{equation}\n",
    "- pour $f(x,y) = \\frac{x}{y}$, \n",
    "  \\begin{equation}\n",
    "    \\frac{\\Delta f^2}{f^2} = \\frac{\\Delta x^2}{x^2} + \\frac{\\Delta y^2}{y^2};\n",
    "  \\end{equation}\n",
    "- pour $f(x) = x^n$, \n",
    "  \\begin{equation}\n",
    "    \\frac{\\Delta f}{f} = n\\frac{\\Delta x}{x}.\n",
    "  \\end{equation}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Il y a d'autres méthodes pour propager les erreurs sur une quantité; notamment, QExPy propose une méthode par Monte Carlo qui permet d'évaluer cette quantité quelque soit la fonction $f$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il y a d'autres méthodes pour propager les erreurs sur une quantité; notamment, QExPy propose une méthode par Monte Carlo qui permet d'évaluer cette quantité quelque soit la fonction $f$.\n",
    "\n",
    "\n",
    "[^details-var]: Pour réaliser ce calcul, on utilise l'hypothèse d'indépendance des valeurs $x_i$ afin de pouvoir écrire $var \\left( \\sum _i x_i \\right) = \\sum _i var \\left(  x_i  \\right)$.\n",
    "\n",
    "\n",
    "\n",
    "````{exercise} \n",
    ":label: vitesse-radar\n",
    "La police utilise généralement des sortes de pistolets radar pour mesurer la vitesse des voitures et détecter celles avec un excès de vitesse.\n",
    "Ce pistolet envoie des ondes radio de fréquence $f_0$ se déplacant avec une vitesse proche de celle de la lumoière $c$ sur une voiture et mesure la fréquence $f$ de l'onde réfléchie.\n",
    "Celle-ci sera différente à cause de l'effet Döppler selon l'équation:\n",
    "\\begin{equation}\n",
    "    f = f_0 \\left( 1- \\frac{v}{c}\\right),\n",
    "\\end{equation}\n",
    "avec $v$ la vitesse de la voiture.\n",
    "Quelle doit être l'incertitude relative de ces pistolets sur la mesure de fréquence pour mesurer la vitesse d'une voiture avec une précision de $1~\\mathrm{km/h}$?\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "````{solution} vitesse-radar\n",
    ":class: dropdown\n",
    "\n",
    "On calcule l'incertitude sur la fréquence à partir de celle sur de la voiture:\n",
    "\n",
    "$$\n",
    "    \\Delta f = \\sqrt{\\left(\\frac{\\mathrm{d}f}{\\mathrm{d}v}\\right)^2\\Delta v^2}\n",
    "    $$\n",
    "\n",
    "$$  = \\sqrt{\\frac{f_0^2}{c^2}}\\Delta v $$\n",
    "\n",
    "$$    \\Rightarrow \\frac{\\Delta f}{f_0} =\\frac{\\Delta v}{c}. $$\n",
    "\n",
    "Pour $c = 10^5~\\mathrm{km/s}$, il faut donc $\\frac{\\Delta f}{f_0} \\approx 3\\times 10^{-6}$.\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "````{exercise} \n",
    ":label: vie-neutron\n",
    "\n",
    "Le coefficient d'asymétrie dans les désintégrations nucléaires $\\beta$ a été réalisée par Bopp et collaborateurs en 1986 {cite:p}`Bopp1986`.\n",
    "A l'aide d'un faisceau de neutrons polarisés, ils ont pu mesurer\n",
    "\n",
    "$$\n",
    "A=\\frac{2 \\lambda(1-\\lambda)}{1+3 \\lambda^{2}}=-0.1146 \\pm 0.0019.\n",
    "$$ (def-A)\n",
    "\n",
    "Cette mesure très précise permet d'en déduire la valeur de $\\lambda$ qui est une quantité essentielle dans les modèles de physique des particules [^couplage].\n",
    "\n",
    "Il est possible de mesurer $\\lambda$ d'une façon assez différente: il suffit de mesurer la durée de vie du neutron libre $\\tau _n$ et d'utiliser la relation:\n",
    "\n",
    "$$\n",
    "\\tau=\\frac{5163.7 \\mathrm{sec}}{1+3 \\lambda^{2}}.\n",
    "$$ (def-tau_n)\n",
    "\n",
    "Cependant les différentes mesures de durée de vie obtenues par les différents groupes ne sont pas consistentes les unes avec les autres.\n",
    "Ci-dessous sont résumées les mesures les plus récentes:\n",
    "\n",
    "- $\\tau _n = 918\\pm 14~\\mathrm{s}$ obtenue par {cite:p}`Christensen1972`,\n",
    "- $\\tau _n = 881\\pm 8~\\mathrm{s}$ obtenue par {cite:p}`Bondarenko1978`,\n",
    "- $\\tau _n = 937\\pm 18~\\mathrm{s}$ obtenue par {cite:p}`Byrne1980`,\n",
    "- $\\tau _n = 887.6\\pm 3.0~\\mathrm{s}$ obtenue par {cite:p}`Mampe1989`.\n",
    "\n",
    "1.  À partir de la relation {eq}`def-tau_n`, trouver une relation donnant $\\lambda$.\n",
    "    Avec une méthode de propagation des erreurs, trouver une relation permettant d'en déduire l'erreur sur $\\lambda$.\n",
    "2.  A partir de cette relation, quelles mesures de $\\tau_n$ sont alors compatibles avec la mesure de $A$?\n",
    "\n",
    "3. Faire un graphique représentant ces différentes mesures et vérifier la compatibilité entre ces résultats.\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "````{solution} vie-neutron\n",
    ":class: dropdown\n",
    "\n",
    "\n",
    "1.  A partir de l'équation \\eqref{eq:def-tau_n}, on trouve:\n",
    "    \\begin{equation}\n",
    "        \\lambda = \\sqrt{\\frac{1}{3}\\left(\\frac{5163.7~\\mathrm{s}}{\\tau}-1\\right)}.\n",
    "    \\end{equation}\n",
    "    On peut alors faire une propagation d'erreur pour trouver l'erreur sur $\\lambda$:\n",
    "    \n",
    "    $$\n",
    "        \\Delta \\lambda = \\sqrt{\\left(\\frac{\\mathrm{d}\\lambda}{\\mathrm{d}\\tau}\\right) ^2 \\Delta \\tau ^2}\n",
    "        $$\n",
    "\n",
    "    $$ = \\Delta \\tau \\sqrt{\\left(\\frac{1}{3}\\frac{5163.7~\\mathrm{s}}{-\\tau ^2 }\\right)^2} $$\n",
    "\n",
    "    $$ = \\frac{5163.7}{3}\\frac{\\Delta \\tau}{\\tau ^2}. $$\n",
    "\n",
    "    On calcule toutes les valeurs de $\\lambda$ associées aux mesures de $\\tau_n$.\n",
    "\n",
    "    ```{code-block} python\n",
    "    from math import sqrt\n",
    "    def compute_lambda(tau):\n",
    "        return sqrt((5163.7/tau-1)/3.)\n",
    "    def compute_errlambda(tau, errtau):\n",
    "        return errtau/(tau**2)*5163.7/3\n",
    "    tau_1972 = 918 # s\n",
    "    tau_1978 = 881 # s\n",
    "    tau_1980 = 937 # s\n",
    "    tau_1989 = 887.6 # s\n",
    "    errtau_1972 = 14 # s\n",
    "    errtau_1978 = 8 # s\n",
    "    errtau_1980 = 18 # s\n",
    "    errtau_1989 = 3.0 # s\n",
    "\n",
    "    lambda_1972 = compute_lambda(tau_1972)\n",
    "    errlambda_1972 = compute_errlambda(tau_1972, errtau_1972)\n",
    "    lambda_1978 = compute_lambda(tau_1978)\n",
    "    errlambda_1978 = compute_errlambda(tau_1978, errtau_1978)\n",
    "    lambda_1980 = compute_lambda(tau_1980)\n",
    "    errlambda_1980 = compute_errlambda(tau_1980, errtau_1980)\n",
    "    lambda_1989 = compute_lambda(tau_1989)\n",
    "    errlambda_1989 = compute_errlambda(tau_1989, errtau_1989)\n",
    "\n",
    "    print(\"lambda(1972)={:.2f}+-{:.2f}\".format(lambda_1972, errlambda_1972))\n",
    "    print(\"lambda(1978)={:.2f}+-{:.2f}\".format(lambda_1978, errlambda_1978))\n",
    "    print(\"lambda(1980)={:.2f}+-{:.2f}\".format(lambda_1980, errlambda_1980))\n",
    "    print(\"lambda(1989)={:.2f}+-{:.2f}\".format(lambda_1989, errlambda_1989))\n",
    "    ```\n",
    "\n",
    "2.  On va calculer la valeur de $A$ pour chaque valeur de $\\lambda$ en utilisant l'équation {eq}`def-A`.\n",
    "    Avec une propagation des erreurs sur $A$, on en déduit que:\n",
    "    \n",
    "    $$\n",
    "        \\Delta A = \\sqrt{ \\Delta\\lambda^2  \\left( \\frac{2(1-2\\lambda)}{1+3\\lambda ^2} - \\frac{6\\lambda\\times 2\\lambda\\times(1-\\lambda)}{(1+3\\lambda^2)^2} \\right)^2}\n",
    "    $$\n",
    "    \n",
    "    $$         = \\left\\vert \\frac{2-4\\lambda-6\\lambda^2}{1+3\\lambda^2}\\right\\vert\\Delta\\lambda. $$\n",
    "    \n",
    "    ```{code-block} python\n",
    "    def compute_A(l):\n",
    "        return (2*l*(1-l)/(1+3*l**2))\n",
    "    def compute_errA(l, errl):\n",
    "        return sqrt(((2-4*l-6*l**2)/((1+3*l**2)**2))**2)*errl\n",
    "\n",
    "    A_1972 = compute_A(lambda_1972)\n",
    "    errA_1972 = compute_errA(lambda_1972, errlambda_1972)\n",
    "    A_1978 = compute_A(lambda_1978)\n",
    "    errA_1978 = compute_errA(lambda_1978, errlambda_1978)\n",
    "    A_1980 = compute_A(lambda_1980)\n",
    "    errA_1980 = compute_errA(lambda_1980, errlambda_1980)\n",
    "    A_1989 = compute_A(lambda_1989)\n",
    "    errA_1989 = compute_errA(lambda_1989, errlambda_1989)\n",
    "\n",
    "    print(\"A(1972)={:.2f}+-{:.2f}\".format(A_1972, errA_1972))\n",
    "    print(\"A(1978)={:.2f}+-{:.2f}\".format(A_1978, errA_1978))\n",
    "    print(\"A(1980)={:.2f}+-{:.2f}\".format(A_1980, errA_1980))\n",
    "    print(\"A(1989)={:.3f}+-{:.3f}\".format(A_1989, errA_1989))\n",
    "    ```\n",
    "\n",
    "    Toutes les valeurs semblent plus ou moins consistantes avec la théorie.\n",
    "    Cependant certaines valeurs notamment celle de 1989 et 1980 semblent peu consistentes (vu la faible barre d'erreur sur la mesure de 1989).\n",
    "\n",
    "3.  ```{code-block} python\n",
    "    import matplotlib.pyplot as plt\n",
    "    list_annees = [1972,1978, 1980, 1989]\n",
    "    list_A = [A_1972, A_1978, A_1980, A_1989]\n",
    "    list_errA = [errA_1972, errA_1978, errA_1980, errA_1989]\n",
    "\n",
    "    fig, axs = plt.subplots(sharey=True, tight_layout=True)\n",
    "    axs.errorbar(list_annees, list_A, yerr=list_errA, fmt = 'o')\n",
    "    axs.set_xlabel(\"Année\")\n",
    "    axs.set_ylabel(\"A\")\n",
    "    axs.axhline(y=-0.1146, color='r', linestyle='-')\n",
    "    ```\n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    "def compute_lambda(tau):\n",
    "    return sqrt((5163.7/tau-1)/3.)\n",
    "def compute_errlambda(tau, errtau):\n",
    "    return errtau/(tau**2)*5163.7/3\n",
    "tau_1972 = 918 # s\n",
    "tau_1978 = 881 # s\n",
    "tau_1980 = 937 # s\n",
    "tau_1989 = 887.6 # s\n",
    "errtau_1972 = 14 # s\n",
    "errtau_1978 = 8 # s\n",
    "errtau_1980 = 18 # s\n",
    "errtau_1989 = 3.0 # s\n",
    "\n",
    "lambda_1972 = compute_lambda(tau_1972)\n",
    "errlambda_1972 = compute_errlambda(tau_1972, errtau_1972)\n",
    "lambda_1978 = compute_lambda(tau_1978)\n",
    "errlambda_1978 = compute_errlambda(tau_1978, errtau_1978)\n",
    "lambda_1980 = compute_lambda(tau_1980)\n",
    "errlambda_1980 = compute_errlambda(tau_1980, errtau_1980)\n",
    "lambda_1989 = compute_lambda(tau_1989)\n",
    "errlambda_1989 = compute_errlambda(tau_1989, errtau_1989)\n",
    "\n",
    "print(\"lambda(1972)={:.2f}+-{:.2f}\".format(lambda_1972, errlambda_1972))\n",
    "print(\"lambda(1978)={:.2f}+-{:.2f}\".format(lambda_1978, errlambda_1978))\n",
    "print(\"lambda(1980)={:.2f}+-{:.2f}\".format(lambda_1980, errlambda_1980))\n",
    "print(\"lambda(1989)={:.2f}+-{:.2f}\".format(lambda_1989, errlambda_1989))\n",
    "\n",
    "\n",
    "def compute_A(l):\n",
    "    return (2*l*(1-l)/(1+3*l**2))\n",
    "def compute_errA(l, errl):\n",
    "    return sqrt(((2-4*l-6*l**2)/((1+3*l**2)**2))**2)*errl\n",
    "\n",
    "A_1972 = compute_A(lambda_1972)\n",
    "errA_1972 = compute_errA(lambda_1972, errlambda_1972)\n",
    "A_1978 = compute_A(lambda_1978)\n",
    "errA_1978 = compute_errA(lambda_1978, errlambda_1978)\n",
    "A_1980 = compute_A(lambda_1980)\n",
    "errA_1980 = compute_errA(lambda_1980, errlambda_1980)\n",
    "A_1989 = compute_A(lambda_1989)\n",
    "errA_1989 = compute_errA(lambda_1989, errlambda_1989)\n",
    "\n",
    "print(\"A(1972)={:.2f}+-{:.2f}\".format(A_1972, errA_1972))\n",
    "print(\"A(1978)={:.2f}+-{:.2f}\".format(A_1978, errA_1978))\n",
    "print(\"A(1980)={:.2f}+-{:.2f}\".format(A_1980, errA_1980))\n",
    "print(\"A(1989)={:.3f}+-{:.3f}\".format(A_1989, errA_1989))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "list_annees = [1972,1978, 1980, 1989]\n",
    "list_A = [A_1972, A_1978, A_1980, A_1989]\n",
    "list_errA = [errA_1972, errA_1978, errA_1980, errA_1989]\n",
    "\n",
    "fig, axs = plt.subplots(sharey=True, tight_layout=True)\n",
    "axs.errorbar(list_annees, list_A, yerr=list_errA, fmt = 'o')\n",
    "axs.set_xlabel(\"Année\")\n",
    "axs.set_ylabel(\"A\")\n",
    "axs.axhline(y=-0.1146, color='r', linestyle='-')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[^couplage]: Cette quantité $\\lambda$ correspond au rapport entre les couplages axiaux et vectoriels pour l'interaction faible.\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":style: alpha\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.0 (main, Oct 25 2022, 13:57:33) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
